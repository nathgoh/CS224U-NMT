{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acaffe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import utils\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "assert device == \"cuda\"\n",
    "\n",
    "# Keep random number generator consistent\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6d4ad9",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017aafbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_sentences, get_vocabs, get_max_len_sentences\n",
    "\n",
    "vocab_en = get_vocabs(\"vocab.en\")\n",
    "vocab_vi = get_vocabs(\"vocab.vi\")\n",
    "\n",
    "# Train sentences\n",
    "train_sentences_en = get_sentences(\"train.en\")\n",
    "train_sentences_vi = get_sentences(\"train.vi\")\n",
    "\n",
    "# Actual test sentences\n",
    "test_sentences_en = get_sentences(\"tst2013.en\")\n",
    "test_sentences_vi = get_sentences(\"tst2013.vi\")\n",
    "\n",
    "# Filter sentences over n words long, in this case 48\n",
    "# The sentences will be n + 2 (50) words long when we include the <s>, </s> tokens\n",
    "MAX_LEN = 48\n",
    "MAX_LEN_WITH_TOKENS = 50\n",
    "\n",
    "train_sentences_en, train_sentences_vi = get_max_len_sentences(train_sentences_en, train_sentences_vi, MAX_LEN)\n",
    "test_sentences_en, test_sentences_vi = get_max_len_sentences(test_sentences_en, test_sentences_vi, MAX_LEN)\n",
    "\n",
    "# Make validation sets\n",
    "val_sentences_en = train_sentences_en[:int(len(train_sentences_en) * 0.1)]\n",
    "val_sentences_vi = train_sentences_vi[:int(len(train_sentences_vi) * 0.1)]\n",
    "\n",
    "# Update training sets\n",
    "train_sentences_en = train_sentences_en[int(len(train_sentences_en) * 0.1):]\n",
    "train_sentences_vi = train_sentences_vi[int(len(train_sentences_vi) * 0.1):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "818610dd",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(108748, 108748)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "len(train_sentences_en), len(train_sentences_vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be2b006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "PAD_INDEX = 0\n",
    "UNK_INDEX = 1\n",
    "SOS_INDEX = 2\n",
    "EOS_INDEX = 3\n",
    "\n",
    "class NMTDataset(data.Dataset):\n",
    "    def __init__(self, source_sentences, source_vocabs, target_sentences, target_vocabs):\n",
    "        self.max_sentence_length = MAX_LEN_WITH_TOKENS\n",
    "\n",
    "        self.source_sentences = source_sentences[:int(len(source_sentences))]\n",
    "        self.target_sentences = target_sentences[:int(len(source_sentences))]\n",
    "\n",
    "        self.source_vocabs = source_vocabs\n",
    "        self.target_vocabs = target_vocabs\n",
    "\n",
    "        self.source_vocab_ids = {v : i for i, v in enumerate(source_vocabs)}\n",
    "        self.source_id_to_vocabs = {val : key for key, val in self.source_vocab_ids.items()}\n",
    "        self.target_vocab_ids = {v : i for i, v in enumerate(target_vocabs)}\n",
    "        self.target_id_to_vocabs = {val : key for key, val in self.target_vocab_ids.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source_sentences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        source_sentence = self.source_sentences[index]\n",
    "    \n",
    "        # Add <s> and </s> to each source sentence\n",
    "        source_len = len(source_sentence) + 2   \n",
    "        source_id = []\n",
    "        for w in source_sentence:\n",
    "            if w not in self.source_vocabs:\n",
    "                w = '<unk>'\n",
    "            source_id.append(self.source_vocab_ids[w])\n",
    "\n",
    "        source_id = ([SOS_INDEX] + source_id + [EOS_INDEX] + [PAD_INDEX] * (self.max_sentence_length - source_len))\n",
    "        \n",
    "        target_sentence = self.target_sentences[index]\n",
    "\n",
    "        # Add <s> and </s> to each target sentence\n",
    "        target_len = len(target_sentence) + 2\n",
    "        target_id = []\n",
    "        for w in target_sentence:\n",
    "            if w not in self.target_vocabs:\n",
    "                w = '<unk>'\n",
    "            target_id.append(self.target_vocab_ids[w])\n",
    "\n",
    "        target_id = ([SOS_INDEX] + target_id + [EOS_INDEX] + [PAD_INDEX] * (self.max_sentence_length - target_len))\n",
    "\n",
    "        return torch.tensor(source_id), source_len, torch.tensor(target_id), target_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacc4c5c",
   "metadata": {},
   "source": [
    "## Attention Encoder Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee9c45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout = 0):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.GRU(input_size, hidden_size, batch_first = True, dropout = dropout, bidirectional = True)\n",
    "    \n",
    "    def forward(self, inputs, lengths):       \n",
    "        packed_inputs = pack_padded_sequence(inputs, lengths.detach().cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_outputs, hidden = self.rnn(packed_inputs)\n",
    "        outputs, output_lengths = pad_packed_sequence(packed_outputs, batch_first = True)\n",
    "\n",
    "        hidden = torch.cat([hidden[0:hidden.size(0):2], hidden[1:hidden.size(0):2]], dim = 2)\n",
    "        \n",
    "        # if outputs.size(1) != 50:\n",
    "        #     outputs = F.pad(input = outputs, pad = (0, 0, 50 - outputs.size(1), 0), mode = 'constant', value = 0)\n",
    "\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbc962ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, attention, dropout = 0):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention = attention\n",
    "        self.rnn = nn.GRU(input_size + 2 * hidden_size, hidden_size, batch_first = True, dropout = dropout)\n",
    "        \n",
    "        # Layer of how we connect the final encoder state as the start for the decoder\n",
    "        self.encoder_to_decoder_layer = nn.Linear(2 * hidden_size, hidden_size) \n",
    "        \n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        self.input_hidden_to_hidden_layer = nn.Linear(input_size + 3 * hidden_size, hidden_size, bias = False)\n",
    "        \n",
    "    def forward_step(self, prev_embed, encoder_hidden, source_mask, proj_key, hidden):\n",
    "\n",
    "        # Context vector for attention mechanism\n",
    "        query = hidden[-1].unsqueeze(1)\n",
    "        context, attention_probs = self.attention(\n",
    "            query = query, \n",
    "            proj_key = proj_key,\n",
    "            value = encoder_hidden,\n",
    "            mask = source_mask\n",
    "        )\n",
    "\n",
    "        # A single decoder step (one word)\n",
    "        rnn_input = torch.cat([prev_embed, context], dim = 2)\n",
    "        rnn_out, hidden_out = self.rnn(rnn_input, hidden)\n",
    "        \n",
    "        output = torch.cat([prev_embed, rnn_out, context], dim = 2)\n",
    "        output = self.dropout_layer(output)\n",
    "        output = self.input_hidden_to_hidden_layer(output)\n",
    "        \n",
    "        return rnn_out, hidden_out, output\n",
    "        \n",
    "    def forward(self, inputs, encoder_hidden, final_encoder_states, source_mask, target_mask, hidden = None, max_len = None):\n",
    "        # Unroll the decoder one step at a time\n",
    "        if max_len is None:\n",
    "            max_len = target_mask.size(-1)\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(final_encoder_states)\n",
    "        \n",
    "        proj_key = self.attention.key_layer(encoder_hidden)\n",
    "\n",
    "        # if proj_key.size(1) != 50:\n",
    "        #     proj_key = F.pad(input = proj_key, pad = (0, 0, 50 - proj_key.size(1), 0), mode = 'constant', value = 0)\n",
    "\n",
    "        # Unrolling for decoder RNN for max_len steps\n",
    "        decoder_states = []\n",
    "        outputs = []\n",
    "\n",
    "        for j in range(max_len):\n",
    "            # if inputs.size(1) != 50:\n",
    "            #     inputs = F.pad(input = inputs, pad = (0, 0, 50 - inputs.size(1), 0), mode = 'constant', value = 0)\n",
    "\n",
    "            prev_embed = inputs[:, j].unsqueeze(1)\n",
    "            rnn_out, hidden_out, output = self.forward_step(prev_embed, encoder_hidden, source_mask, proj_key, hidden)\n",
    "            decoder_states.append(rnn_out)\n",
    "            outputs.append(output)\n",
    "        \n",
    "        decoder_states = torch.cat(decoder_states, dim = 1)\n",
    "        outputs = torch.cat(outputs, dim = 1)\n",
    "\n",
    "        return decoder_states, hidden, outputs\n",
    "            \n",
    "    def init_hidden(self, final_encoder_states):\n",
    "        # Initialize first decoder hidden state using the final encoder hidden states\n",
    "        return torch.tanh(self.encoder_to_decoder_layer(final_encoder_states))\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b47ad3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderAttentionDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, source_embed, target_embed, generator):\n",
    "        super(EncoderAttentionDecoder, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.source_embed = source_embed\n",
    "        self.target_embed = target_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, source_ids, target_ids, source_mask, target_mask, source_lengths):\n",
    "        encoder_hidden, final_encoder_states = self.encode(source_ids, source_lengths)\n",
    "        return self.decode(encoder_hidden, final_encoder_states, source_mask, target_ids[:, :-1], target_mask)\n",
    "\n",
    "    def encode(self, source_ids, source_lengths):\n",
    "        return self.encoder(self.source_embed(source_ids), source_lengths)\n",
    "\n",
    "    def decode(self, encoder_hidden, final_encoder_states, source_mask, target_ids, target_mask, decoder_hidden=None):\n",
    "        return self.decoder(self.target_embed(target_ids), encoder_hidden, final_encoder_states, source_mask, target_mask, decoder_hidden) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "748ebd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    # Define standard linear and softmax generation step\n",
    "    def __init__(self, hidden_size, vocab_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, key_size = None, query_size = None):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "\n",
    "        key_size = 2 * hidden_size if key_size is None else key_size\n",
    "        query_size = hidden_size if query_size is None else query_size\n",
    "\n",
    "        self.alphas = None\n",
    "        self.query_layer = nn.Linear(query_size, hidden_size, bias = False)\n",
    "        self.key_layer = nn.Linear(key_size, hidden_size, bias = False)\n",
    "        self.energy_layer = nn.Linear(hidden_size, 1, bias = False)\n",
    "    \n",
    "    def forward(self, query, proj_key, value, mask):\n",
    "        query = self.query_layer(query)\n",
    "        scores = self.energy_layer(torch.tanh(query + proj_key))\n",
    "\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        if scores.size(2) != 50:\n",
    "            scores = F.pad(input = scores, pad = (0, 50 - scores.size(2), 0, 0), mode = 'constant', value = 0)\n",
    "\n",
    "        scores.data.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        alphas = F.softmax(scores, dim = -1)\n",
    "        self.alphas = alphas\n",
    "\n",
    "        if value.size(1) != 50:\n",
    "            value = F.pad(input = value, pad = (0, 0, 50 - value.size(1), 0), mode = 'constant', value = 0)\n",
    "\n",
    "        context = torch.bmm(alphas, value)\n",
    "\n",
    "        return context, alphas      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2865b8bc",
   "metadata": {},
   "source": [
    "## Training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "285fdae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class LossCompute:\n",
    "    def __init__(self, generator, criterion, opt = None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "\n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)), y.contiguous().view(-1))\n",
    "        loss = loss / norm\n",
    "\n",
    "        # Training mode\n",
    "        if self.opt is not None:  \n",
    "            loss.backward()          \n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "\n",
    "        return loss.data.item() * norm\n",
    "\n",
    "def run_epoch(data_loader, model, loss_compute, print_every):\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    for j, (source_ids_batch, source_lengths_batch, target_ids_batch, target_lengths_batch) in enumerate(data_loader):       \n",
    "        source_ids_batch = source_ids_batch.to(device)\n",
    "        source_lengths_batch = source_lengths_batch.to(device)\n",
    "        source_mask_batch = (source_ids_batch != PAD_INDEX).unsqueeze(-2)\n",
    "\n",
    "        target_ids_batch = target_ids_batch.to(device)\n",
    "        target_mask_batch = target_ids_batch[:, 1:] != PAD_INDEX\n",
    "\n",
    "        out, _, output = model.forward(source_ids_batch, target_ids_batch, source_mask_batch, target_mask_batch, source_lengths_batch)\n",
    "\n",
    "        loss = loss_compute(x = output, y = target_ids_batch[:, 1:], norm = source_ids_batch.size(0))\n",
    "        total_loss += loss\n",
    "        total_tokens += (target_ids_batch[:, 1:] != PAD_INDEX).data.sum().item()\n",
    "\n",
    "        if model.training and j % print_every == 0:\n",
    "              print(\"Epoch Step: {} Loss: {}\".format(j, loss / source_ids_batch.size(0)))\n",
    "\n",
    "    return math.exp(total_loss / float(total_tokens))\n",
    "\n",
    "def train(model, num_epochs, learning_rate, print_every):\n",
    "    # ignore_index as PAD_INDEX so that pad tokens won't be included when computing the loss\n",
    "    criterion = nn.NLLLoss(reduction = \"sum\", ignore_index = PAD_INDEX)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    # Keep track of dev perplexity for each epoch.\n",
    "    dev_perplexities = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch\", epoch)\n",
    "\n",
    "        model.train()\n",
    "        train_perplexity = run_epoch(data_loader = train_data_loader, model = model, loss_compute = LossCompute(model.generator, criterion, optim), print_every = print_every)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():      \n",
    "            dev_perplexity = run_epoch(data_loader = val_data_loader, model = model, loss_compute = LossCompute(model.generator, criterion, None), print_every = print_every)\n",
    "            print(\"Validation perplexity: {}\".format(dev_perplexity))\n",
    "            dev_perplexities.append(dev_perplexity)\n",
    "        \n",
    "    return dev_perplexities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c75482",
   "metadata": {},
   "source": [
    "## Attention Encoder Decoder Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d512046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Vietnamese to English\n",
    "train_set = NMTDataset(train_sentences_vi, vocab_vi, train_sentences_en, vocab_en)\n",
    "train_data_loader = data.DataLoader(train_set, batch_size = batch_size, num_workers = 2, shuffle=True)\n",
    "\n",
    "val_set = NMTDataset(val_sentences_vi, vocab_vi, val_sentences_en, vocab_en)\n",
    "val_data_loader = data.DataLoader(val_set, batch_size = batch_size, num_workers = 2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6edfe13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/nathgoh/anaconda3/envs/nlu/lib/python3.8/site-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "Epoch 0\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (50) must match the size of tensor b (49) at non-singleton dimension 2",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fd87d1b2ddf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Training, returns dev_perplexities, a list of dev perplexity for each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mpure_dev_perplexities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_seq2seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0003\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_seq2seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"attention_seq2seq.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-be40d15b37c9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, num_epochs, learning_rate, print_every)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mtrain_perplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_compute\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLossCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-be40d15b37c9>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(data_loader, model, loss_compute, print_every)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mtarget_mask_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_ids_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mPAD_INDEX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_ids_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ids_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_mask_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mask_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_lengths_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_ids_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource_ids_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-6b1588a098b9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, source_ids, target_ids, source_mask, target_mask, source_lengths)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_encoder_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_encoder_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-6b1588a098b9>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, encoder_hidden, final_encoder_states, source_mask, target_ids, target_mask, decoder_hidden)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_encoder_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_encoder_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b0557104da57>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, encoder_hidden, final_encoder_states, source_mask, target_mask, hidden, max_len)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mprev_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mrnn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproj_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mdecoder_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b0557104da57>\u001b[0m in \u001b[0;36mforward_step\u001b[0;34m(self, prev_embed, encoder_hidden, source_mask, proj_key, hidden)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Context vector for attention mechanism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         context, attention_probs = self.attention(\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mproj_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproj_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlu/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-931706c1fd18>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, proj_key, value, mask)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#     scores = F.pad(input = scores, pad = (0, 50 - scores.size(2), 0, 0), mode = 'constant', value = 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1e9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (50) must match the size of tensor b (49) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "from utils import plot_perplexity\n",
    "\n",
    "# Hyperparameters \n",
    "embed_size = 256   # Each word will be represented as a `embed_size`-dim vector.\n",
    "hidden_size = 512  # RNN hidden size\n",
    "dropout = 0.1\n",
    "\n",
    "attention_seq2seq = EncoderAttentionDecoder(\n",
    "    encoder = Encoder(embed_size, hidden_size, dropout = dropout),\n",
    "    decoder = AttentionDecoder(embed_size, hidden_size, attention = BahdanauAttention(hidden_size), dropout = dropout),\n",
    "    source_embed = nn.Embedding(len(vocab_vi), embed_size),\n",
    "    target_embed = nn.Embedding(len(vocab_en), embed_size),\n",
    "    generator = Generator(hidden_size, len(vocab_en))).to(device)\n",
    "\n",
    "train_model = True\n",
    "if train_model:\n",
    "    # Training, returns dev_perplexities, a list of dev perplexity for each epoch\n",
    "    pure_dev_perplexities = train(attention_seq2seq, num_epochs = 10, learning_rate = 0.0003, print_every = 100)\n",
    "    torch.save(attention_seq2seq.state_dict(), \"attention_seq2seq.pt\")\n",
    "\n",
    "    # Plot perplexity\n",
    "    plot_perplexity(pure_dev_perplexities)\n",
    "else:\n",
    "    attention_seq2seq.load_state_dict(torch.load(\"attention_seq2seq.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "EncoderAttentionDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (rnn): GRU(256, 512, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  )\n",
       "  (decoder): AttentionDecoder(\n",
       "    (attention): BahdanauAttention(\n",
       "      (query_layer): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (key_layer): Linear(in_features=1024, out_features=512, bias=False)\n",
       "      (energy_layer): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (rnn): GRU(1280, 512, batch_first=True, dropout=0.1)\n",
       "    (encoder_to_decoder_layer): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dropout_layer): Dropout(p=0.1, inplace=False)\n",
       "    (input_hidden_to_hidden_layer): Linear(in_features=1792, out_features=512, bias=False)\n",
       "  )\n",
       "  (source_embed): Embedding(7710, 256)\n",
       "  (target_embed): Embedding(17192, 256)\n",
       "  (generator): Generator(\n",
       "    (proj): Linear(in_features=512, out_features=17192, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "attention_seq2seq"
   ]
  },
  {
   "source": [
    "## Attention Decoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(model, source_ids, source_lengths, max_len):\n",
    "    with torch.no_grad():\n",
    "        source_mask = (source_ids != PAD_INDEX).unsqueeze(-2)\n",
    "        encoder_hiddens, final_encoder_states = model.encode(source_ids, source_lengths)\n",
    "        prev_y = torch.ones(1, 1).fill_(SOS_INDEX).type_as(source_ids)\n",
    "        target_mask = torch.ones_like(prev_y)\n",
    "\n",
    "    output = []\n",
    "    attention_scores = []\n",
    "    hidden = None\n",
    "\n",
    "    for i in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            rnn_out, hidden, outputs = model.decode(encoder_hiddens, final_encoder_states, source_mask, prev_y, target_mask, hidden)\n",
    "            prob = model.generator(outputs[:, -1])\n",
    "            d, next_word = torch.max(prob, dim = 1)\n",
    "            next_word = next_word.data.item()\n",
    "            output.append(next_word)\n",
    "            prev_y = torch.ones(1, 1).type_as(source_ids).fill_(next_word)\n",
    "            attention_scores.append(model.decoder.attention.alphas.cpu().numpy())\n",
    "            \n",
    "    output = np.array(output)\n",
    "\n",
    "    EOS_mask = np.where(output == EOS_INDEX)\n",
    "    if len(EOS_mask[0]) > 0:\n",
    "        output = output[:EOS_mask[0][0]]\n",
    "\n",
    "    return output, attention_scores"
   ]
  },
  {
   "source": [
    "## Attention Examples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import lookup_words\n",
    "\n",
    "def print_examples(model, source_vocab, target_vocab, data_loader, decoder, attention = False, n = 3, EOS_INDEX = 3, max_len = 50):\n",
    "\n",
    "    model.eval()\n",
    "        \n",
    "    for j, (source_ids, source_lengths, target_ids, target_lengths) in enumerate(data_loader):\n",
    "        if not attention:\n",
    "            result = decoder(model, source_ids.to(device), source_lengths.to(device), max_len = max_len)\n",
    "        else:\n",
    "            result, _ = decoder(model, source_ids.to(device), source_lengths.to(device), max_len = max_len)\n",
    "\n",
    "        # Remove <s>\n",
    "        source_ids = source_ids[0, 1:]\n",
    "        target_ids = target_ids[0, 1:]\n",
    "\n",
    "        # Remove </s> and <pad>\n",
    "        source_ids = source_ids[:np.where(source_ids == EOS_INDEX)[0][0]]\n",
    "        target_ids = target_ids[:np.where(target_ids == EOS_INDEX)[0][0]]\n",
    "\n",
    "        prediction = \" \".join(utils.lookup_words(result, vocab = target_vocab))\n",
    "        target = \" \".join(utils.lookup_words(target_ids, vocab = target_vocab))\n",
    "   \n",
    "        print(\"Example {}\".format(j + 1))\n",
    "        print(\"Source : \", \" \".join(lookup_words(source_ids, vocab = source_vocab)))\n",
    "        print(\"Target : \", \" \".join(lookup_words(target_ids, vocab = target_vocab)))\n",
    "        print(\"Prediction: \", \" \".join(lookup_words(result, vocab = target_vocab)))\n",
    "        print()\n",
    "        \n",
    "        if j == n - 1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Attention Encoder-Decoder Results:\n",
      "Example 1\n",
      "Source :  Khoa học đằng sau một tiêu đề về khí hậu\n",
      "Target :  Rachel <unk> : The science behind a climate headline\n",
      "Prediction:  So the <unk> .\n",
      "\n",
      "Example 2\n",
      "Source :  Tôi muốn cho các bạn biết về sự to lớn của những nỗ lực khoa học đã góp phần làm nên các dòng tít bạn thường thấy trên báo .\n",
      "Target :  I &apos;d like to talk to you today about the scale of the scientific effort that goes into making the headlines you see in the paper .\n",
      "Prediction:  I want to do is the <unk> .\n",
      "\n",
      "Example 3\n",
      "Source :  Có những dòng trông như thế này khi bàn về biến đổi khí hậu , và như thế này khi nói về chất lượng không khí hay khói bụi .\n",
      "Target :  <unk> that look like this when they have to do with climate change , and headlines that look like this when they have to do with air quality or smog .\n",
      "Prediction:  There are the same .\n",
      "\n",
      "Example 4\n",
      "Source :  Cả hai đều là một nhánh của cùng một lĩnh vực trong ngành khoa học khí quyển .\n",
      "Target :  They are both two branches of the same field of atmospheric science .\n",
      "Prediction:  The <unk> .\n",
      "\n",
      "Example 5\n",
      "Source :  Các tiêu đề gần đây trông như thế này khi Ban Điều hành Biến đổi khí hậu Liên chính phủ , gọi tắt là IPCC đưa ra bài nghiên cứu của họ về hệ thống khí quyển .\n",
      "Target :  Recently the headlines looked like this when the <unk> Panel on Climate Change , or IPCC , put out their report on the state of understanding of the atmospheric system .\n",
      "Prediction:  The <unk> .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "attention_examples = NMTDataset(val_sentences_vi, vocab_vi, val_sentences_en, vocab_en)\n",
    "attention_example_data_loader = data.DataLoader(attention_examples, batch_size = 1, num_workers = 1, shuffle = False)\n",
    "\n",
    "print(\"Attention Encoder-Decoder Results:\")\n",
    "print_examples(attention_seq2seq, vocab_vi, vocab_en, attention_example_data_loader, decode, True, n = 5)"
   ]
  },
  {
   "source": [
    "## BLEU Testing\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "\n",
    "def compute_BLEU(model, data_loader, decoder, target_vocabs, attention = False):\n",
    "  bleu_score = []\n",
    "\n",
    "  model.eval()\n",
    "  for source_ids, source_lengths, target_ids, _ in data_loader:\n",
    "    if not attention:\n",
    "      result = decoder(model, source_ids.to(device), source_lengths.to(device), max_len = MAX_LEN_WITH_TOKENS)\n",
    "    else:\n",
    "      result, _ = decoder(model, source_ids.to(device), source_lengths.to(device), max_len = MAX_LEN_WITH_TOKENS)\n",
    "\n",
    "    # Remove <s>\n",
    "    source_ids = source_ids[0, 1:]\n",
    "    target_ids = target_ids[0, 1:]\n",
    "\n",
    "    # Remove </s> and <pad>\n",
    "    source_ids = source_ids[:np.where(source_ids == EOS_INDEX)[0][0]]\n",
    "    target_ids = target_ids[:np.where(target_ids == EOS_INDEX)[0][0]]\n",
    "\n",
    "    prediction = \" \".join(utils.lookup_words(result, vocab=target_vocabs))\n",
    "    target = \" \".join(utils.lookup_words(target_ids, vocab=target_vocabs))\n",
    "\n",
    "    bleu_score.append(sacrebleu.raw_corpus_bleu([prediction], [[target]], .01).score)\n",
    "\n",
    "  return bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BLEU score with Attention: 2.411732704113133\n"
     ]
    }
   ],
   "source": [
    "test_set = NMTDataset(test_sentences_vi, vocab_vi, test_sentences_en, vocab_en)\n",
    "test_data_loader = data.DataLoader(test_set, batch_size = 1, num_workers = 2, shuffle = False)\n",
    "\n",
    "print(\"BLEU score with Attention: {}\".format(np.mean(compute_BLEU(attention_seq2seq, test_data_loader, decode, vocab_en, True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd033a1378092e5cd1eb85e90719efd5bd5246634928c384bfd2d4c8ebeefa4de1b",
   "display_name": "Python 3.8.5 64-bit ('nlu': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}