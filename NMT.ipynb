{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acaffe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "assert device == \"cuda\"\n",
    "\n",
    "# Keep random number generator consistent\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6d4ad9",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017aafbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_sentences, get_vocabs, get_max_len_sentences\n",
    "\n",
    "vocab_en = get_vocabs(\"vocab.50K.en\")\n",
    "vocab_de = get_vocabs(\"vocab.50K.de\")\n",
    "\n",
    "# Train sentences\n",
    "train_sentences_en = get_sentences(\"train.en\")\n",
    "train_sentences_de = get_sentences(\"train.de\")\n",
    "\n",
    "# Actual test sentences\n",
    "test_sentences_en = get_sentences(\"newstest2015.en\")\n",
    "test_sentences_de = get_sentences(\"newstest2015.de\")\n",
    "\n",
    "# Filter sentences over n words long, in this case 48\n",
    "# The sentences will be n + 2 (50) words long when we include the <s>, </s> tokens\n",
    "MAX_LEN = 48\n",
    "MAX_LEN_WITH_TOKENS = 50\n",
    "\n",
    "train_sentences_en, train_sentences_de = get_max_len_sentences(train_sentences_en, train_sentences_de, MAX_LEN)\n",
    "test_sentences_en, test_sentences_de = get_max_len_sentences(test_sentences_en, test_sentences_de, MAX_LEN)\n",
    "\n",
    "# Make validation set\n",
    "val_sentences_en = train_sentences_en[:int(len(train_sentences_en) * 0.1)]\n",
    "val_sentences_de = train_sentences_de[:int(len(train_sentences_de) * 0.1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "818610dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4033382, 4033382)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences_en), len(train_sentences_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be2b006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "PAD_INDEX = 0\n",
    "UNK_INDEX = 1\n",
    "SOS_INDEX = 2\n",
    "EOS_INDEX = 3\n",
    "\n",
    "class NMTDataset(data.Dataset):\n",
    "    def __init__(self, source_sentences, source_vocabs, target_sentences, target_vocabs):\n",
    "        self.max_sentence_length = MAX_LEN_WITH_TOKENS\n",
    "\n",
    "        self.source_sentences = source_sentences[:int(len(source_sentences))]\n",
    "        self.target_sentences = target_sentences[:int(len(source_sentences))]\n",
    "\n",
    "        self.source_vocabs = source_vocabs\n",
    "        self.target_vocabs = target_vocabs\n",
    "\n",
    "        self.source_vocab_ids = {v : i for i, v in enumerate(source_vocabs)}\n",
    "        self.source_id_to_vocabs = {val : key for key, val in self.source_vocab_ids.items()}\n",
    "        self.target_vocab_ids = {v : i for i, v in enumerate(target_vocabs)}\n",
    "        self.target_id_to_vocabs = {val : key for key, val in self.target_vocab_ids.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source_sentences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        source_sentence = self.source_sentences[index]\n",
    "    \n",
    "        # Add <s> and </s> to each source sentence\n",
    "        source_len = len(source_sentence) + 2   \n",
    "        source_id = []\n",
    "        for w in source_sentence:\n",
    "            if w not in self.source_vocabs:\n",
    "                w = '<unk>'\n",
    "            source_id.append(self.source_vocab_ids[w])\n",
    "\n",
    "        source_id = ([SOS_INDEX] + source_id + [EOS_INDEX] + [PAD_INDEX] * (self.max_sentence_length - source_len))\n",
    "        target_sentence = self.target_sentences[index]\n",
    "\n",
    "        # Add <s> and </s> to each target sentence\n",
    "        target_len = len(target_sentence) + 2\n",
    "        target_id = []\n",
    "        for w in target_sentence:\n",
    "            if w not in self.target_vocabs:\n",
    "                w = '<unk>'\n",
    "            target_id.append(self.target_vocab_ids[w])\n",
    "\n",
    "        target_id = ([SOS_INDEX] + target_id + [EOS_INDEX] + [PAD_INDEX] * (self.max_sentence_length - target_len))\n",
    "\n",
    "        return torch.tensor(source_id), source_len, torch.tensor(target_id), target_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacc4c5c",
   "metadata": {},
   "source": [
    "## Baseline Encoder Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee9c45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout = 0):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            input_size: RNN input size\n",
    "            hidden_size: RNN hidden size\n",
    "            dropout: Dropout rate during training\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, bias = True, dropout = dropout)\n",
    "    \n",
    "    def forward(self, inputs, lengths):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            inputs: (batch_size, max_sentence_length, embed_size) batch of padded embedded word vectors of source\n",
    "            sentences\n",
    "            lengths: (batch_size, ) sequence length of inputs\n",
    "        Outputs:\n",
    "            outputs: (batch_size, max_sentence_length, hidden_size)\n",
    "            hidden: (num_layers, batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        \n",
    "        packed_inputs = pack_padded_sequence(inputs, lengths.detach().cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_outputs, hidden = self.rnn(packed_inputs)\n",
    "        outputs, output_lengths = pad_packed_sequence(packed_outputs)\n",
    "        \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbc962ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout = 0):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            input_size: same as Encoder\n",
    "            hidden_size: same as Encoder\n",
    "            dropout: same as Encoder\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, bias = True, dropout = dropout)\n",
    "        \n",
    "        # Layer of how we connect the final encoder state as the start for the decoder\n",
    "        self.encoder_to_decoder_layer = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        self.input_hidden_to_hidden_layer = nn.Linear(input_size + hidden_size, hidden_size, bias = False)\n",
    "        \n",
    "    def forward_step(self, prev_embed, hidden):\n",
    "        # Does a single decoder step (one word)\n",
    "        rnn_out, hidden_out = self.rnn(prev_embed, hidden)\n",
    "        \n",
    "        output = torch.cat([prev_embed, rnn_out], dim = 2)\n",
    "        output = self.dropout_layer(output)\n",
    "        output = self.input_hidden_to_hidden_layer(output)\n",
    "        \n",
    "        return rnn_out, hidden_out, output\n",
    "        \n",
    "    def forward(self, inputs, final_encoder_states, hidden = None, max_len = None):\n",
    "        # Unroll the decoder one step at a time\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "          inputs: (batch_size, max_sentence_length, embed_size) batch of padded embedded word vectors of target\n",
    "          sentences (for teacher-forcing during training)\n",
    "          final_encoder_states: (num_encoder_layers, batch_size, hidden_size) final encoder hidden states used \n",
    "          to initialize the initial decoder hidden states\n",
    "          hidden: (1, batch_size, hidden_size) value to be used to initialize the initial decoder hidden states.\n",
    "          max_len: Max decoding length.\n",
    "\n",
    "        Returns:\n",
    "          outputs: (batch_size, max_seq_length, hidden_size) raw decoder outputs \n",
    "          hidden: (1, batch_size, hidden_size) last decoder hidden state.\n",
    "        \"\"\"\n",
    "        if max_len is None:\n",
    "            max_len = inputs.size(1)\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(final_encoder_states)\n",
    "            \n",
    "        # Unrolling for decoder RNN for max_len steps\n",
    "        decoder_states = []\n",
    "        outputs = []\n",
    "        for j in range(max_len):\n",
    "            prev_embed = inputs[:, j].unsqueeze(1)\n",
    "            rnn_out, hidden_out, output = self.forward_step(prev_embed, hidden)\n",
    "            decoder_states.append(rnn_out)\n",
    "            outputs.append(out)\n",
    "        \n",
    "        decoder_states = torch.cat(decoder_states, dim = 1)\n",
    "        outputs = torch.cat(outputs, dim = 1)\n",
    "        \n",
    "        return hidden, outputs\n",
    "            \n",
    "    def init_hidden(self, final_encoder_states):\n",
    "        # Initialize first decoder hidden state using the final encoder hidden states\n",
    "        return torch.tanh(self.encoder_to_decoder_layer(final_encoder_states))\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b47ad3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, source_embed, target_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            encoder: Encoder object\n",
    "            decoder: Decoder object\n",
    "            source_embed: nn.Embedding object, the lookup table for source sentences\n",
    "            target_emebd: nn.Embedding object, the lookup table for target sentences\n",
    "            generator: Linear mapping\n",
    "        \"\"\"\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.source_embed = source_embed\n",
    "        self.target_embed = target_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, source_ids, target_ids, source_lengths):\n",
    "        # Take in and process masked source and target sequences\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "          source_ids: (batch_size, max_sentence_length) batch of source sentences of word ids.\n",
    "          target_ids: (batch_size, max_sentence_length) batch of target sentences of word ids.\n",
    "          source_lengths: (batch_size,) sequence length of sentence_ids`.\n",
    "        Outputs:\n",
    "            Returns the decoder outputs\n",
    "        \"\"\"\n",
    "        encoder_hiddens, encoder_finals = self.encode(source_ids, source_lengths)\n",
    "        return self.decode(encoder_finals, target_ids[:, :-1])\n",
    "\n",
    "    def encode(self, source_ids, source_lengths):\n",
    "        return self.encoder(self.source_embed(source_ids), source_lengths)\n",
    "\n",
    "    def decode(self, encoder_finals, target_ids, decoder_hidden=None):\n",
    "        return self.decoder(self.target_embed(target_ids), encoder_finals, decoder_hidden) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "748ebd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "  # Define standard linear and softmax generation step\n",
    "    def __init__(self, hidden_size, vocab_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2865b8bc",
   "metadata": {},
   "source": [
    "## Training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "285fdae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class SimpleLossCompute:\n",
    "    # A simple loss compute and train function\n",
    "\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "\n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)), y.contiguous().view(-1))\n",
    "        loss = loss / norm\n",
    "\n",
    "        # Training mode\n",
    "        if self.opt is not None:  \n",
    "            loss.backward()          \n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "\n",
    "        return loss.data.item() * norm\n",
    "\n",
    "\n",
    "def run_epoch(data_loader, model, loss_compute, print_every):\n",
    "    # Standard Training and Logging Function\n",
    "\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    for j, (source_ids_BxT, source_lengths_B, target_ids_BxL, target_lengths_B) in enumerate(data_loader):\n",
    "        \"\"\"\n",
    "        B: batch size\n",
    "        T: max sequence length of source sentences (50)\n",
    "        L: max sequence length of target sentences (50)\n",
    "        source_ids_BxT (when B = 2) Example:\n",
    "          [[2, 4, 6, 7, ..., 4, 3, 0, 0, 0],\n",
    "           [2, 8, 6, 5, ..., 9, 5, 4, 3, 0]]\n",
    "        source_lengths_B for above example: [47, 49].\n",
    "        \"\"\"\n",
    "\n",
    "        source_ids_BxT = source_ids_BxT.to(device)\n",
    "        source_lengths_B = source_lengths_B.to(device)\n",
    "        target_ids_BxL = target_ids_BxL.to(device)\n",
    "        \n",
    "        _, output = model(source_ids_BxT, target_ids_BxL, source_lengths_B)\n",
    "\n",
    "        loss = loss_compute(x = output, y = target_ids_BxL[:, 1:], norm = source_ids_BxT.size(0))\n",
    "        total_loss += loss\n",
    "        total_tokens += (target_ids_BxL[:, 1:] != PAD_INDEX).data.sum().item()\n",
    "\n",
    "        if model.training and j % print_every == 0:\n",
    "              print(\"Epoch Step: {} Loss: {}\".format(i, loss / source_ids_BxT.size(0)))\n",
    "\n",
    "    return math.exp(total_loss / float(total_tokens))\n",
    "\n",
    "def train(model, num_epochs, learning_rate, print_every):\n",
    "    # Set `ignore_index` as PAD_INDEX so that pad tokens won't be included when computing the loss\n",
    "    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index = PAD_INDEX)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    # Keep track of dev perplexity for each epoch.\n",
    "    dev_perplexities = []\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch\", epoch)\n",
    "\n",
    "        model.train()\n",
    "        train_perplexity = run_epoch(data_loader=train_data_loader, model=model, loss_compute=SimpleLossCompute(model.generator, criterion, optim), print_every=print_every)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():      \n",
    "            dev_perplexity = run_epoch(data_loader = val_data_loader, model=model, loss_compute = SimpleLossCompute(model.generator, criterion, None), print_every = print_every)\n",
    "            print(\"Validation perplexity: {}\".format(dev_perplexity))\n",
    "            dev_perplexities.append(dev_perplexity)\n",
    "        \n",
    "    return dev_perplexities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c75482",
   "metadata": {},
   "source": [
    "## Baseline Encoder Decoder Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d512046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# English to German\n",
    "train_set = NMTDataset(train_sentences_en, vocab_en, train_sentences_de, vocab_de)\n",
    "train_data_loader = data.DataLoader(train_set, batch_size = batch_size, num_workers = 4, shuffle=True)\n",
    "\n",
    "val_set = NMTDataset(val_sentences_en, vocab_en, val_sentences_de, vocab_de)\n",
    "val_data_loader = data.DataLoader(val_set, batch_size = batch_size, num_workers = 4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6edfe13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a5eebdbc825f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Training, returns dev_perplexities, a list of dev perplexity for each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mpure_dev_perplexities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_seq2seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpure_seq2seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"baseline_seq2seq.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ffaa59480478>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, num_epochs, learning_rate, print_every)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mtrain_perplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_compute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSimpleLossCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_every\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-ffaa59480478>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(data_loader, model, loss_compute, print_every)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtarget_ids_BxL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_ids_BxL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_ids_BxT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ids_BxL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_lengths_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_ids_BxL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource_ids_BxT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-146dd1a1625e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, source_ids, target_ids, source_lengths)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \"\"\"\n\u001b[1;32m     28\u001b[0m         \u001b[0mencoder_hiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_finals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_finals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-146dd1a1625e>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, encoder_finals, target_ids, decoder_hidden)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_finals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_finals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-1451b0666bde>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, final_encoder_states, hidden, max_len)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_encoder_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# Unrolling for decoder RNN for max_len steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-1451b0666bde>\u001b[0m in \u001b[0;36minit_hidden\u001b[0;34m(self, final_encoder_states)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_encoder_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# Initialize first decoder hidden state using the final encoder hidden states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_to_decoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_encoder_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtens_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "# Hyperparameters \n",
    "embed_size = 256   # Each word will be represented as a `embed_size`-dim vector.\n",
    "hidden_size = 512  # RNN hidden size.\n",
    "dropout = 0.2\n",
    "\n",
    "baseline_seq2seq = EncoderDecoder(\n",
    "    encoder = Encoder(embed_size, hidden_size, dropout = dropout),\n",
    "    decoder = Decoder(embed_size, hidden_size, dropout = dropout),\n",
    "    source_embed = nn.Embedding(len(vocab_en), embed_size),\n",
    "    target_embed = nn.Embedding(len(vocab_de), embed_size),\n",
    "    generator = Generator(hidden_size, len(vocab_de))).to(device)\n",
    "\n",
    "train_model = True\n",
    "if train_model:\n",
    "    # Training, returns dev_perplexities, a list of dev perplexity for each epoch\n",
    "    pure_dev_perplexities = train(baseline_seq2seq, num_epochs = 10, learning_rate = 1e-3, print_every = 100)\n",
    "    torch.save(pure_seq2seq.state_dict(), \"baseline_seq2seq.pt\")\n",
    "\n",
    "    # Plot perplexity\n",
    "    utils.plot_perplexity(pure_dev_perplexities)\n",
    "else:\n",
    "    baseline_seq2seq.load_state_dict(torch.load(\"baseline_seq2seq.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bdd42e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}